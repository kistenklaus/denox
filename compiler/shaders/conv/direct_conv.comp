#version 460

#extension GL_EXT_control_flow_attributes : require
#extension GL_KHR_memory_scope_semantics : require
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
#extension GL_EXT_shader_explicit_arithmetic_types : require
#extension GL_EXT_shader_16bit_storage                   : require
#extension GL_EXT_scalar_block_layout : require
#extension GL_KHR_shader_subgroup_basic                  : enable
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_shuffle_relative : require
#extension GL_EXT_shader_subgroup_extended_types_int16 : enable

// Vectorized memory storage type.
// NOTE: After loading from global memory we can always vectorize.
// For example for register to shared memory copy or coopMatLoad from shared memory.
#define vstype uvec4
#define VSTYPE_SIZE 16

layout(set = 0, binding = 0, std430) readonly buffer input_buf {
    istype input_tensor_blob[];
};

layout(set = 0, binding = 1, std430) writeonly buffer output_buf {
    // NOTE: The output tensor memory.
    // We currently support:
    // -f16:
    // ---HWC: anything goes, but best performance if IN_CH is divisible by 8 (HWC8).
    // ---CHWC8: comparible performance with HWC8.
    ostype output_tensor_blob[];
};

layout(set = 0, binding = 2, std430) readonly buffer filter_buf {
    fstype filter_blob[];
};

#ifdef USE_BIAS
layout(set = 0, binding = 3, std430) readonly buffer bias_buf {
    // NOTE: The bias blob is required to be aligned to 16byte and
    // padded to a multiple of CM_N.
    // This allows us to skip shared memory when loading the bias.
    vstype bias_blob[];
};
#endif

layout(push_constant) uniform PushConstant {
    uint IN_W;
    uint IN_H;
} pc;


void main() {

}
